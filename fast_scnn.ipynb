{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "from Fast_SCNN import get_fast_scnn\n",
    "\n",
    "from tensorflow.python.client import device_lib\n",
    "\n",
    "def get_available_gpus():\n",
    "    local_device_protos = device_lib.list_local_devices()\n",
    "    return [x.name for x in local_device_protos if x.device_type == 'GPU']\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/device:GPU:0']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_available_gpus()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "AUTOTUNE = tf.data.experimental.AUTOTUNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "    \n",
    "def load_pickle(filename):\n",
    "    \n",
    "    item_pkl_file = open(filename, 'rb')\n",
    "    item = pickle.load(item_pkl_file)\n",
    "    \n",
    "    return item"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "root_dir = '/mnt/windows/projects/data/'\n",
    "import timeit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "images_train = load_pickle(root_dir + \"images_train_mini.pickle\")\n",
    "labels_train = load_pickle(root_dir + \"labels_train_mini.pickle\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "images_utrain = np.asarray(images_train) / 255.0\n",
    "\n",
    "labels_train = np.asarray(labels_train)\n",
    "\n",
    "images_utrain = images_utrain.reshape(images_utrain.shape[0],images_utrain.shape[2],images_utrain.shape[1],images_utrain.shape[3])\n",
    "\n",
    "labels_train = labels_train.reshape(labels_train.shape[0],labels_train.shape[2],labels_train.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(500, 512, 512, 3) (500, 64, 64)\n"
     ]
    }
   ],
   "source": [
    "print(images_utrain.shape, labels_train.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(500, 64, 64, 20)\n"
     ]
    }
   ],
   "source": [
    "labels_train_categorical = tf.keras.utils.to_categorical(labels_train, 20)\n",
    "print(labels_train_categorical.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "image_count = len(images_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "images_val = load_pickle(root_dir + \"images_val_mini_100.pickle\")\n",
    "labels_val = load_pickle(root_dir + \"labels_val_mini_100.pickle\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "images_uval = np.asarray(images_val) / 255.0\n",
    "\n",
    "labels_val = np.asarray(labels_val)\n",
    "\n",
    "images_uval = images_uval.reshape(images_uval.shape[0],images_uval.shape[2],images_uval.shape[1],images_uval.shape[3])\n",
    "\n",
    "labels_val = labels_val.reshape(labels_val.shape[0],labels_val.shape[2],labels_val.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20, 64, 64, 20)\n"
     ]
    }
   ],
   "source": [
    "labels_val_categorical = tf.keras.utils.to_categorical(labels_val, 20)\n",
    "print(labels_val_categorical.shape)\n",
    "#print(labels_val_categorical)\n",
    "image_count_val = len(images_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time:  1.7354137339989393\n"
     ]
    }
   ],
   "source": [
    "start = timeit.default_timer()\n",
    "\n",
    "image_ds_train = tf.data.Dataset.from_tensor_slices(images_utrain)\n",
    "label_ds_train = tf.data.Dataset.from_tensor_slices(labels_train_categorical)\n",
    "\n",
    "image_ds_val = tf.data.Dataset.from_tensor_slices(images_uval)\n",
    "label_ds_val = tf.data.Dataset.from_tensor_slices(labels_val_categorical)\n",
    "\n",
    "stop = timeit.default_timer()\n",
    "print('Time: ', stop - start) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<TensorSliceDataset shapes: (512, 512, 3), types: tf.float64> <TensorSliceDataset shapes: (64, 64, 20), types: tf.float32>\n"
     ]
    }
   ],
   "source": [
    "print(image_ds_train, label_ds_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "image_label_ds = tf.data.Dataset.zip((image_ds_train, label_ds_train))\n",
    "image_label_val_ds = tf.data.Dataset.zip((image_ds_val, label_ds_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<ZipDataset shapes: ((512, 512, 3), (64, 64, 20)), types: (tf.float64, tf.float32)>\n",
      "<ZipDataset shapes: ((512, 512, 3), (64, 64, 20)), types: (tf.float64, tf.float32)>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "500"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(image_label_ds)\n",
    "print(image_label_val_ds)\n",
    "image_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<PrefetchDataset shapes: ((None, 512, 512, 3), (None, 64, 64, 20)), types: (tf.float64, tf.float32)>"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BATCH_SIZE = 8\n",
    "\n",
    "# Setting a shuffle buffer size as large as the dataset ensures that the data is\n",
    "# completely shuffled.\n",
    "ds = image_label_ds.shuffle(buffer_size=image_count)\n",
    "ds = ds.repeat()\n",
    "ds = ds.batch(BATCH_SIZE)\n",
    "# `prefetch` lets the dataset fetch batches, in the background while the model is training.\n",
    "ds = ds.prefetch(buffer_size=AUTOTUNE)\n",
    "ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<PrefetchDataset shapes: ((None, 512, 512, 3), (None, 64, 64, 20)), types: (tf.float64, tf.float32)>"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds = image_label_ds.apply(tf.data.experimental.shuffle_and_repeat(buffer_size = image_count))\n",
    "ds = ds.batch(BATCH_SIZE)\n",
    "ds = ds.prefetch(buffer_size=AUTOTUNE)\n",
    "ds\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<PrefetchDataset shapes: ((None, 512, 512, 3), (None, 64, 64, 20)), types: (tf.float64, tf.float32)>"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#BATCH_SIZE = 8\n",
    "\n",
    "# Setting a shuffle buffer size as large as the dataset ensures that the data is\n",
    "# completely shuffled.\n",
    "val_ds = image_label_val_ds.shuffle(buffer_size=image_count_val)\n",
    "val_ds = val_ds.repeat()\n",
    "val_ds = val_ds.batch(BATCH_SIZE)\n",
    "# `prefetch` lets the dataset fetch batches, in the background while the model is training.\n",
    "val_ds = val_ds.prefetch(buffer_size=AUTOTUNE)\n",
    "val_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<PrefetchDataset shapes: ((None, 512, 512, 3), (None, 64, 64, 20)), types: (tf.float64, tf.float32)>"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_ds = image_label_val_ds.apply(tf.data.experimental.shuffle_and_repeat(buffer_size = image_count_val))\n",
    "val_ds = val_ds.batch(BATCH_SIZE)\n",
    "val_ds = val_ds.prefetch(buffer_size=AUTOTUNE)\n",
    "val_ds\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gfe_layer.shape: (None, 32, 32, 64)\n",
      "gfe_layer.shape: (None, 16, 16, 96)\n",
      "gfe_layer.shape: (None, 16, 16, 128)\n",
      "16 16\n",
      "x in paramid.shape (None, 16, 16, 128)\n",
      "x in paramid.shape (None, 16, 16, 128)\n",
      "x in paramid.shape (None, 16, 16, 128)\n",
      "x in paramid.shape (None, 16, 16, 128)\n",
      "gfe_layer.shape: (None, 16, 16, 256)\n",
      "ff_layer1.shape (None, 64, 64, 128)\n",
      "ff_layer2.shape (None, 64, 64, 256)\n",
      "ff_layer2.shape (None, 64, 64, 256)\n",
      "ff_layer2.shape (None, 64, 64, 128)\n",
      "ff_final.shape (None, 64, 64, 128)\n",
      "classifier.shape (None, 64, 64, 128)\n",
      "classifier.shape (None, 64, 64, 128)\n",
      "classifier.shape (None, 64, 64, 20)\n",
      "classifier before upsampling: (None, 64, 64, 20)\n"
     ]
    }
   ],
   "source": [
    "fast_scnn = get_fast_scnn(512,512,20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Only tried on limited epochs to make sure the algorithm learns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "63/63 [==============================] - 257s 4s/step - loss: 1.6742 - accuracy: 0.5493 - val_loss: 2.1127 - val_accuracy: 0.4774\n",
      "Epoch 2/5\n",
      "63/63 [==============================] - 257s 4s/step - loss: 1.5743 - accuracy: 0.5785 - val_loss: 1.9813 - val_accuracy: 0.4651\n",
      "Epoch 3/5\n",
      "63/63 [==============================] - 258s 4s/step - loss: 1.5174 - accuracy: 0.5987 - val_loss: 1.9836 - val_accuracy: 0.4803\n",
      "Epoch 4/5\n",
      "63/63 [==============================] - 264s 4s/step - loss: 1.4712 - accuracy: 0.6110 - val_loss: 1.6498 - val_accuracy: 0.5846\n",
      "Epoch 5/5\n",
      "63/63 [==============================] - 257s 4s/step - loss: 1.4365 - accuracy: 0.6195 - val_loss: 1.5724 - val_accuracy: 0.6142\n"
     ]
    }
   ],
   "source": [
    "es = tf.keras.callbacks.EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=20)\n",
    "\n",
    "model_history = fast_scnn.fit(ds, epochs = 5, validation_data = val_ds, callbacks = [es])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
